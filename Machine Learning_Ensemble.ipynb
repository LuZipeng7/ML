{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f40c5c-a2ed-43f2-b1f2-6e651f2805b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import gc\n",
    "#データの読み込み\n",
    "def getExperimentalData(file):\n",
    "    path = os.getcwd()+\"/../data_ml/\" #データがあるフォルダの指定\n",
    "    data = pd.read_excel(path + file, sheet_name='result') #データの読み込み\n",
    "    data_log = data.copy()\n",
    "    return data, data_log\n",
    "\n",
    "#欠損値を除いたデータセットの作成\n",
    "def getDataset(data, param):\n",
    "    df = data.dropna(subset=[param]) # \"param\"列に欠損値がある行を削除\n",
    "    return df\n",
    "\n",
    "#出力ディレクトリの設定\n",
    "def makeTdDir():\n",
    "    folder_path = os.getcwd()+ \"/../graph\" #グラフを保存するフォルダのパスを指定\n",
    "    if not os.path.isdir(folder_path): #指定したフォルダがない時\n",
    "        os.mkdir(folder_path) #指定したフォルダを作成\n",
    "    td = dt.today() #今日の日付の設定\n",
    "    tdstr = td.strftime('%y%m%d') #今日の日付を6桁の文字列で受け取る\n",
    "    td_path = folder_path + \"/graph\" + tdstr #今日作成したグラフを保存するフォルダのパスを指定\n",
    "    if not os.path.isdir(td_path):\n",
    "        os.mkdir(td_path)\n",
    "    return tdstr, td_path + \"/\" \n",
    "\n",
    "def makeDir(param):\n",
    "    if not os.path.isdir(td_path + param):\n",
    "        os.mkdir(td_path + param) #出力パラメータごとのファイルを作成\n",
    "    return td_path + param+\"/\"\n",
    "\n",
    "tdstr,td_path = makeTdDir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663caa9f-f5a5-4c11-8ab3-1e116e660a6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikeras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_pipeline\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscikeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasRegressor\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[0;32m     14\u001b[0m param_grid_svr\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m     15\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m18\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m14\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m     16\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     17\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0\u001b[39m]}\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikeras'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "param_grid_svr={\"C\":[2**-5,2**-3,2**-1,2**1,2**3,2**5,2**7,2**9,2**11],\n",
    "                \"gamma\":[2**-20,2**-18,2**-16,2**-14,2**-12,2**-10,2**-8,2**-6,2**-4,2**-2,2**0,2**2,2**4,2**6,2**8,2**10],\n",
    "                \"kernel\":[\"rbf\"],\n",
    "                  \"epsilon\":[2**-10,2**-8,2**-6,2**-4,2**-2,2**0]}\n",
    "\n",
    "param_grid_gbdt = {\"learning_rate\":[i/100 for i in range(1,51,1)],  \n",
    "                   \"max_depth\":[2,3,4,5],\n",
    "                   \"n_estimators\":[300]}\n",
    "\n",
    "param_grid_knn={\"n_neighbors\":[1,2,3,4]}\n",
    "\n",
    "\n",
    "def NN_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(16, activation='relu', input_dim=len(variable)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6ddad-c55c-486b-8646-2b7c9d54792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#個体の各遺伝子を決めるために使用\n",
    "import random\n",
    "#DEAPの中にある必要なモジュールをインポート\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from deap import algorithms\n",
    "\n",
    "# Define a custom mutation function for floats\n",
    "def mutate_float(individual, low, up, indpb):\n",
    "    for i, val in enumerate(individual):\n",
    "        if random.random() < indpb:\n",
    "            individual[i] = random.uniform(low, up)\n",
    "    return individual,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0d79e-4672-4a01-9d83-717cbc89b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b27221-ddea-4ee4-a771-d62081052729",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable=data.columns[4:]\n",
    "variable\n",
    "param=\"Max Rate (1/h)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a9e70-ba55-49ed-8000-9c3eae79d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = StandardScaler()\n",
    "minmax = MinMaxScaler()\n",
    "\n",
    "data_scaled=data[variable].copy()\n",
    "data_scaled[data_scaled.columns] = standard.fit_transform(data_scaled)\n",
    "data_scaled[data_scaled.columns] = minmax.fit_transform(data_scaled)\n",
    "data_scaled[param]=data[param]\n",
    "    \n",
    "mlp = KerasRegressor(model=NN_model, batch_size=16, epochs=100,verbose=0)\n",
    "gbdt=GridSearchCV(GradientBoostingRegressor(),param_grid_gbdt,cv=5)\n",
    "svr=GridSearchCV(SVR(),param_grid_svr,cv=5)\n",
    "knn=GridSearchCV(KNeighborsRegressor(),param_grid_knn,cv=5)\n",
    "    \n",
    "gbdt.fit(data_scaled[variable] , data_scaled[param])\n",
    "svr.fit(data_scaled[variable] , data_scaled[param])\n",
    "knn.fit(data_scaled[variable] , data_scaled[param])\n",
    "\n",
    "\n",
    "final=pd.DataFrame()\n",
    "num=1\n",
    "\n",
    "while num<11:\n",
    "    \n",
    "    data_scaled=data[variable].copy()\n",
    "    data_scaled[data_scaled.columns] = standard.transform(data_scaled)\n",
    "    data_scaled[data_scaled.columns] = minmax.transform(data_scaled)\n",
    "    data_scaled[\"Max Rate (1/h)\"]=data[\"Max Rate (1/h)\"]\n",
    "\n",
    "    gbdt_en=GradientBoostingRegressor(**gbdt.best_params_)\n",
    "    svr_en=SVR(**svr.best_params_)\n",
    "    knn_en=KNeighborsRegressor(**knn.best_params_)\n",
    "    estimators = [\n",
    "            ('svr', svr_en),\n",
    "            (\"gbdt\",gbdt_en),\n",
    "            ('mlp', mlp),\n",
    "            ('knn', knn_en)]\n",
    "    \n",
    "    model= StackingRegressor(estimators=estimators,final_estimator=LinearRegression())\n",
    "    model.fit(data_scaled[variable] , data_scaled[param])\n",
    "\n",
    "    #最大化問題として設定\n",
    "    creator.create( \"FitnessMax\", base.Fitness, weights=(1.0,) )\n",
    "    #個体の定義（list型と指定しただけで、中身の遺伝子は後で入れる）\n",
    "    creator.create(\"Individual\", list, fitness = creator.FitnessMax )\n",
    "\n",
    "    # 目的関数の定義\n",
    "\n",
    "    def evaluate(individual):\n",
    "\n",
    "        arti_data=pd.DataFrame(individual).T\n",
    "        arti_data.columns=variable\n",
    "\n",
    "        prediction = model.predict(arti_data)\n",
    "        return prediction,\n",
    "\n",
    "    #各種関数の設定を行います\n",
    "    toolbox = base.Toolbox()\n",
    "    #random.uniformの別名をattribute関数として設定。各個体の遺伝子の中身を決める関数(各遺伝子は0～10のランダムな整数)\n",
    "    toolbox.register(\"attribute\", random.uniform, 0.01,1.0)\n",
    "    #individualという関数を設定。それぞれの個体に含まれる6個の遺伝子をattributeにより決めるよ、ということ。\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attribute, len(variable))\n",
    "    #集団の個体数を設定するための関数を準備\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    #トーナメント方式で次世代に子を残す親を選択（tornsizeは各トーナメントに参加する個体の数）\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=5)\n",
    "    #交叉関数の設定。一点交叉を採用\n",
    "    toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "    #突然変異関数の設定。indpbは各遺伝子が突然変異を起こす確率。変異は0~20の整数で変異\n",
    "    toolbox.register(\"mutate\", mutate_float, low=0.2, up=2.0, indpb=0.2)\n",
    "    #評価したい関数の設定（目的関数のこと）\n",
    "    toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "    #乱数の固定\n",
    "    random.seed(128)\n",
    "    #何世代まで行うか\n",
    "    NGEN = 50\n",
    "    #集団の個体数\n",
    "    POP = 300\n",
    "    #交叉確率\n",
    "    CXPB = 0.9\n",
    "    #個体が突然変異を起こす確率\n",
    "    MUTPB = 0.2\n",
    "    #集団は80個体という情報の設定\n",
    "    pop = toolbox.population(n=POP)\n",
    "\n",
    "    #集団内の個体それぞれの適応度（目的関数の値）を計算\n",
    "    for ind in pop:\n",
    "        ind.fitness.values = toolbox.evaluate(ind)\n",
    "\n",
    "    #パレート曲線上の個体(つまり、良い結果の個体)をhofという変数に格納\n",
    "    hof = tools.ParetoFront()\n",
    "\n",
    "    #最も単純なSimple GAという進化戦略を採用\n",
    "    algorithms.eaSimple(pop, toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=NGEN, halloffame=hof)\n",
    "\n",
    "    #最終的な集団(pop)からベストな個体を1体選出する関数\n",
    "    best_ind = tools.selBest(pop, 1)[0]\n",
    "\n",
    "    artificial=pd.DataFrame(best_ind).T\n",
    "    artificial.columns=variable\n",
    "    \n",
    "    #スケーリング\n",
    "    artificial[artificial.columns] = minmax.inverse_transform(artificial)\n",
    "    artificial[artificial.columns] = standard.inverse_transform(artificial)  # scalerはモデル構築時に使用したスケーラー\n",
    "    \n",
    "        \n",
    "    artificial[\"predicted\"]=best_ind.fitness.values[0][0]\n",
    "    \n",
    "    final=pd.concat([final, artificial])\n",
    "    \n",
    "    artificial[\"Max Rate (1/h)\"]=0\n",
    "    data=pd.concat([data, artificial])\n",
    "    \n",
    "    num+=1\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011aa52a-d241-45ba-a554-e6e67aed7939",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f68cf1-93b2-42c0-ba88-52711b63e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path=makeDir(\"prediction_result\")\n",
    "final.to_csv(path + tdstr + \"_media_prediction_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
